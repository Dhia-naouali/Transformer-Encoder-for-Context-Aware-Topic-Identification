{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":534371,"sourceType":"datasetVersion","datasetId":254267}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, re, math, nltk, torch\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nnltk.download(\"stopwords\", quiet=True)\nstop_words = set(stopwords.words(\"english\"))\n\nspecial_tokens = [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\", \"<NUM>\"]\nbatch_size=32\npath = \"/kaggle/input/dbpedia-classes\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:43.257658Z","iopub.execute_input":"2025-01-06T22:06:43.258027Z","iopub.status.idle":"2025-01-06T22:06:43.265168Z","shell.execute_reply.started":"2025-01-06T22:06:43.258003Z","shell.execute_reply":"2025-01-06T22:06:43.264010Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_path = os.path.join(path, \"DBPEDIA_train.csv\")\ntest_path = os.path.join(path, \"DBPEDIA_test.csv\")\nval_path = os.path.join(path, \"DBPEDIA_val.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:44.356826Z","iopub.execute_input":"2025-01-06T22:06:44.357137Z","iopub.status.idle":"2025-01-06T22:06:44.361482Z","shell.execute_reply.started":"2025-01-06T22:06:44.357113Z","shell.execute_reply":"2025-01-06T22:06:44.360533Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def preprocess(path, config):\n    df = pd.read_csv(path)\n    df['label'] = df['l3']\n    df.drop(columns=[\"l1\", \"l2\", \"l3\"], inplace=True)\n    df[\"len\"] = df[\"text\"].apply(len)\n    df = df[df[\"len\"] < config.max_words]\n    \n    def tokenize(text, stop_words):\n        tokens = re.split(f\"\\W+\", text.lower())\n        words_tokens = [\"<SOS>\"]\n        words_tokens += [token if token.isalpha() else \"<NUM>\" for token in tokens if token and token not in stop_words]\n        words_tokens += [\"<EOS>\"]\n        return words_tokens\n\n\n    def build_vocab(tokens, min_freq=3):\n        vocab_counter = Counter(word for seq in tokens for word in seq)\n        vocab = {'<PAD>': 0, '<UNK>': 1, \"<SOS>\": 2, \"<EOS>\": 3, '<NUM>': 4}\n        for token, freq in vocab_counter.items():\n            if token not in special_tokens and freq >= min_freq:\n                vocab[token] = len(vocab)\n        return vocab\n\n    def encode_tokens(tokens, vocab, seq_len):\n        encoded = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n        if len(encoded) < seq_len:\n            encoded += [vocab[\"<PAD>\"]] * (seq_len - len(encoded))\n        else:\n            encoded = encoded[:seq_len]\n        return encoded\n\n    df[\"tokens\"] = df[\"text\"].apply(lambda x: tokenize(x, config.stop_words))\n    if config.vocab is None:\n        vocab = build_vocab(df[\"tokens\"])\n        config.vocab = vocab\n        \n    print(f\"vocab size: {len(config.vocab)}\")\n\n    seq_len = df[\"tokens\"].apply(len)\n    max_len = seq_len.max()\n    \n    print(f\"seq len max: {max_len}, mean: {seq_len.mean()}\")\n    \n    df[\"encoded_text\"] = df[\"tokens\"].apply(lambda x: encode_tokens(x, config.vocab, max_len))\n    \n    if config.label_vocab is None:\n        config.label_vocab = {label: idx for idx, label in enumerate(df[\"label\"].unique())}\n\n    print(f\"num_labels: {len(config.label_vocab)}\")\n    \n    df[\"encoded_label\"] = df[\"label\"].apply(lambda x: config.label_vocab[x])\n    df.reset_index(drop=True, inplace=True)\n    \n    return df[[\"encoded_text\", \"encoded_label\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:45.498704Z","iopub.execute_input":"2025-01-06T22:06:45.499009Z","iopub.status.idle":"2025-01-06T22:06:45.510615Z","shell.execute_reply.started":"2025-01-06T22:06:45.498987Z","shell.execute_reply":"2025-01-06T22:06:45.509471Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class Config:\n    def __init__(self, stop_words=stop_words):\n        self.vocab = None\n        self.label_vocab = None\n        self.max_words = 360\n        self.stop_words = stop_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:46.996961Z","iopub.execute_input":"2025-01-06T22:06:46.997323Z","iopub.status.idle":"2025-01-06T22:06:47.001802Z","shell.execute_reply.started":"2025-01-06T22:06:46.997293Z","shell.execute_reply":"2025-01-06T22:06:47.000840Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, text, label):\n        self.text = text\n        self.label = label\n\n    def __len__(self):\n        return len(self.label)\n\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.text[idx], dtype=torch.long), torch.tensor(self.label[idx], dtype=torch.long)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:47.157433Z","iopub.execute_input":"2025-01-06T22:06:47.157856Z","iopub.status.idle":"2025-01-06T22:06:47.162997Z","shell.execute_reply.started":"2025-01-06T22:06:47.157827Z","shell.execute_reply":"2025-01-06T22:06:47.162059Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"config = Config()\ndf_train = preprocess(train_path, config)\ndf_test = preprocess(test_path, config)\ndf_val = preprocess(val_path, config)\nlen(config.vocab), len(config.label_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:47.356978Z","iopub.execute_input":"2025-01-06T22:06:47.357314Z","iopub.status.idle":"2025-01-06T22:06:56.349358Z","shell.execute_reply.started":"2025-01-06T22:06:47.357288Z","shell.execute_reply":"2025-01-06T22:06:56.348379Z"}},"outputs":[{"name":"stdout","text":"vocab size: 43928\nseq len max: 68, mean: 25.67092819075198\nnum_labels: 219\nvocab size: 43928\nseq len max: 56, mean: 25.629540347293155\nnum_labels: 219\nvocab size: 43928\nseq len max: 61, mean: 25.67331687919923\nnum_labels: 219\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(43928, 219)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:56.350423Z","iopub.execute_input":"2025-01-06T22:06:56.350735Z","iopub.status.idle":"2025-01-06T22:06:56.362346Z","shell.execute_reply.started":"2025-01-06T22:06:56.350694Z","shell.execute_reply":"2025-01-06T22:06:56.361603Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                        encoded_text  encoded_label\n0  [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, ...              0\n1  [2, 1, 1, 32, 33, 34, 35, 36, 37, 38, 39, 40, ...              1\n2  [2, 4, 48, 4, 49, 50, 4, 4, 49, 48, 4, 49, 50,...              2\n3  [2, 52, 53, 54, 55, 56, 57, 53, 54, 58, 4, 4, ...              3\n4  [2, 1, 1, 65, 4, 4, 66, 67, 68, 4, 4, 66, 67, ...              4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoded_text</th>\n      <th>encoded_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 4, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[2, 1, 1, 32, 33, 34, 35, 36, 37, 38, 39, 40, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[2, 4, 48, 4, 49, 50, 4, 4, 49, 48, 4, 49, 50,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[2, 52, 53, 54, 55, 56, 57, 53, 54, 58, 4, 4, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[2, 1, 1, 65, 4, 4, 66, 67, 68, 4, 4, 66, 67, ...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"x_train = np.array(df_train[\"encoded_text\"].tolist())\nx_test = np.array(df_test[\"encoded_text\"].tolist())\nx_val = np.array(df_val[\"encoded_text\"].tolist())\n\ny_train = np.array(df_train[\"encoded_label\"].tolist())\ny_test = np.array(df_test[\"encoded_label\"].tolist())\ny_val = np.array(df_val[\"encoded_label\"].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:56.363954Z","iopub.execute_input":"2025-01-06T22:06:56.364204Z","iopub.status.idle":"2025-01-06T22:06:56.934639Z","shell.execute_reply.started":"2025-01-06T22:06:56.364182Z","shell.execute_reply":"2025-01-06T22:06:56.933693Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_dataset = TextDataset(x_train, y_train)\ntest_dataset = TextDataset(x_test, y_test)\nval_dataset = TextDataset(x_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:56.935845Z","iopub.execute_input":"2025-01-06T22:06:56.936169Z","iopub.status.idle":"2025-01-06T22:06:56.942631Z","shell.execute_reply.started":"2025-01-06T22:06:56.936142Z","shell.execute_reply":"2025-01-06T22:06:56.941391Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"x_train.shape, x_test.shape, x_val.shape, y_train.shape, y_test.shape, y_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:06:56.943611Z","iopub.execute_input":"2025-01-06T22:06:56.944127Z","iopub.status.idle":"2025-01-06T22:06:56.960242Z","shell.execute_reply.started":"2025-01-06T22:06:56.944087Z","shell.execute_reply":"2025-01-06T22:06:56.959433Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"((97383, 68), (24475, 56), (14586, 61), (97383,), (24475,), (14586,))"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PosEmb(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(10000) / (half_dim - 1)\n        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n        emb = x[:, None] * emb[None, :]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb\n\n\nclass Enc_Transformer(nn.Module):\n    def __init__(self, vocab_size, num_classes, emb_dim=256, num_heads=8):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim)\n        self.emb.weight.data *= 1e-3\n        self.pos_emb = PosEmb(emb_dim)\n\n        self.multihead_attn = nn.MultiheadAttention(emb_dim, num_heads=num_heads, batch_first=True)\n        self.mlp = nn.Sequential(\n            nn.Linear(emb_dim, 4*emb_dim),\n            nn.ELU(inplace=True),\n            nn.Linear(4*emb_dim, emb_dim),\n            nn.LayerNorm(emb_dim),\n        )\n        self.fc_out = nn.Linear(emb_dim, num_classes)\n\n\n    def forward(self, input_seq):\n        bs, l = input_seq.shape\n        emb_seq = self.emb(input_seq)\n        seq_idx = torch.arange(l, device=input_seq.device)\n        pos_emb = self.pos_emb(seq_idx).reshape(1, l, -1).expand(bs, l, -1)\n        emb_seq += pos_emb\n\n        output, attn_map = self.multihead_attn(emb_seq, emb_seq, emb_seq)\n        output = self.mlp(output).mean(dim=1)\n        return self.fc_out(output), attn_map\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:07:28.757709Z","iopub.execute_input":"2025-01-06T22:07:28.758076Z","iopub.status.idle":"2025-01-06T22:07:28.767716Z","shell.execute_reply.started":"2025-01-06T22:07:28.758048Z","shell.execute_reply":"2025-01-06T22:07:28.766427Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nvocab_size = len(config.vocab)\nnum_classes = len(config.label_vocab)\nepochs = 2\nlearning_rate=1e-4\nmodel = Enc_Transformer(vocab_size, num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nlr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:10:36.262448Z","iopub.execute_input":"2025-01-06T22:10:36.262875Z","iopub.status.idle":"2025-01-06T22:10:36.407719Z","shell.execute_reply.started":"2025-01-06T22:10:36.262844Z","shell.execute_reply":"2025-01-06T22:10:36.406880Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"\ntrain_acc_hist = []\ntrain_loss_hist = []\n\nval_acc_hist = []\nval_loss_hist = []\n\ntrain_acc, test_acc = 0, 0\n\nfor epoch in range(epochs):\n    # Training\n    model.train()\n    correct = total = train_loss = 0\n    \n    for text, label in tqdm(train_loader):\n        text, label = text.to(device), label.to(device)\n        pred, _ = model(text)\n        \n        loss = criterion(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        correct += (pred.argmax(1) == label).sum().item()\n        total += label.size(0)\n        train_loss += loss.item()\n    \n    # Calculate epoch metrics\n    train_acc = correct / total\n    train_loss = train_loss / len(train_loader)\n    train_acc_hist.append(train_acc)\n    train_loss_hist.append(train_loss)\n    \n    lr_scheduler.step()\n    \n    # Validation\n    model.eval()\n    val_correct = val_total = val_loss = 0\n    \n    with torch.no_grad():\n        for text, label in test_loader:\n            text, label = text.to(device), label.to(device)\n            pred, _ = model(text)\n            loss = criterion(pred, label)\n            \n            val_correct += (pred.argmax(1) == label).sum().item()\n            val_total += label.size(0)\n            val_loss += loss.item()\n\n    val_acc = val_correct / val_total\n    val_loss = val_loss / len(test_loader)\n    val_acc_hist.append(val_acc)\n    val_loss_hist.append(val_loss)\n    \n    print(f\"epoch {epoch+1}/{epochs} acc: {train_acc:.4f}, val_acc: {val_acc:.4f}, loss: {train_loss:.4f}, val_loss: {val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T22:10:39.147178Z","iopub.execute_input":"2025-01-06T22:10:39.147556Z","iopub.status.idle":"2025-01-06T22:11:35.723258Z","shell.execute_reply.started":"2025-01-06T22:10:39.147480Z","shell.execute_reply":"2025-01-06T22:11:35.722250Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3043/3043 [00:25<00:00, 118.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1/2 acc: 0.4752, val_acc: 0.8935, loss: 2.7544, val_loss: 0.5236\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3043/3043 [00:25<00:00, 117.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2/2 acc: 0.9246, val_acc: 0.9236, loss: 0.3442, val_loss: 0.3449\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}